# Translate

## Abstract

我们解决了以动作为条件生成逼真多样的人体运动序列的问题。 与完成或扩展运动序列的方法相比，此任务不需要初始姿势或序列。 在这里，我们通过训练生成变分自动编码器 (VAE) 来学习人体动作的动作感知潜在表示。 通过从这个潜在空间中采样并通过一系列位置编码查询某个持续时间，我们合成了以分类动作为条件的可变长度运动序列。 具体来说，我们**设计了一个基于 Transformer 的架构 ACTOR，用于编码和解码从动作识别数据集估计的一系列参数化 SMPL 人体模型**。 我们在 NTU RGB+D、HumanAct12 和 UESTC 数据集上评估了我们的方法，并展示了对现有技术的改进。 此外，我们还展示了两个用例：通过将我们的合成数据添加到训练中来改进动作识别，以及运动去噪。 代码和模型可在我们的项目页面 [57] 上找到。

## Introduction

尽管对人体运动建模进行了数十年的研究 [4、5]，但合成逼真且可控的序列仍然极具挑战性。 在这项工作中，我们的目标是采用像“投掷”这样的语义动作标签，并生成无限数量的逼真 3D 人体运动序列，长度各不相同，看起来像真实的投掷（图 1）。大量先前的工作都集中在采取一个姿势或一系列姿势，然后预测未来的运动 [3、6、22、71、74]。 这是一个过于受限的场景，因为它假设已经有一个运动序列并且只需要更多。 另一方面，许多应用程序，如虚拟现实和角色控制 [28、61] 需要生成具有指定持续时间的给定类型（语义动作标签）的动作。

> 图1：目标：以动作为条件的 Transformer VAE（ACTOR）学习合成以分类动作和持续时间T为条件的人类运动序列。序列是通过从单一的运动表征潜伏向量z中取样产生的，而不是先前工作中的框架级嵌入空间。

我们通过使用具有相应动作标签的 3D 人体运动数据训练动作条件生成模型来解决这个问题。特别是，我们**构建了一个基于 Transformer 的编码器-解码器架构，并使用 VAE 目标对其进行训练**。 我们使用 SMPL [46] 对人体进行参数化，因为它可以输出关节位置或身体表面。 这为更好地模拟与环境的相互作用铺平了道路，因为表面是模拟接触所必需的。 此外，这种表示允许使用多种重建损失：约束运动树中的零件旋转、关节位置或表面点。文献 [40] 和我们的结果表明，损失的组合给出了最真实的生成运动。

运动合成的关键挑战是生成在感知上逼真的同时具有多样性的序列。许多运动生成方法都采用**自回归方法**，例如 LSTM [16] 和 GRU [49]。然而，<u>这些方法通常会在一段时间后回归到平均姿势 [49] 并且容易漂移</u>。 我们的 Transformer 模型的**关键创新是为解码器提供位置编码并立即输出完整序列**。 最近关于神经辐射场的工作已经普及了位置编码 [50]； 我们还没有看到它像我们一样用于运动生成。 这允许生成可变长度序列，而不会出现运动回归到平均姿势的问题。 此外，据我们所知，我们的方法是第一个**创建动作条件序列级嵌入**的方法。 最接近的工作是 Action2Motion [21]，相比之下，它提出了一种自回归方法，其中潜在表示处于帧级别。 获得序列级嵌入需要汇集时间维度：我们为此目的引入了一种结合 Transformers 和 VAE 的新方法，这也显着提高了基线的性能。

我们的动作条件生成问题的一个特定挑战是存在与不同动作标签配对的有限动作捕捉 (MoCap) 数据，通常在 10 个类别中 [31、63]。 相反，我们依靠单目运动估计方法 [38] 来获得 3D 动作序列，并在 UESTC 动作识别数据集 [32] 的 40 个细粒度类别上呈现有希望的结果。 与[21]相反，我们不需要多视角相机来进行单目轨迹估计，这使得我们的模型可能适用于更大的尺度。 尽管有噪音，单眼估计被证明足以用于训练，并且作为我们模型的额外好处，我们能够通过我们学习的运动表示来编码解码去噪估计序列。 

动作条件生成模型可以增强现有的 MoCap 数据集，这些数据集昂贵且大小有限 [48,63]。 最近的研究提供了用于训练动作识别模型的合成人类动作视频 [65]，显示了动作多样性和每个动作的大量数据的重要性。 这种方法可以受益于无限源动作条件运动合成。 我们通过动作识别实验来探讨这个问题。 我们观察到，**尽管存在 domain gap，但生成的运动可以作为额外的训练数据，尤其是在低数据设置中**。 最后，紧凑的动作感知人体运动潜在空间可以用作其他任务的先决条件，例如视频中的人体运动估计。

我们的贡献有四方面：(i) 我们介绍了 ACTOR，这是一种新型的基于 Transformer 的条件 VAE，并训练它通过从序列级潜在向量中采样来生成动作条件人体运动。 (ii) 我们证明可以使用从单眼视频估计的嘈杂 3D 人体姿势来学习生成逼真的 3D 人体运动； (iii) 我们对架构和损失组件进行全面的消融研究，在多个数据集上获得最先进的性能； (iv) 我们为动作识别和 MoCap 去噪模型说明了两个用例。 该代码可在我们的项目页面 [57] 上找到。

## Related Work

我们简要回顾了有关运动预测、运动合成、单眼运动估计以及 VAE 背景下的 Transformers 的相关文献。

**未来人体运动预测。**人体运动分析的研究历史悠久，可以追溯到 20 世纪 80 年代 [5,17,19,52]。 给定过去的运动或初始姿势，预测未来的帧被称为运动预测。 早期研究中已经采用了统计模型 [7, 18]。
最近，随着 GANs [20] 或 VAEs [37] 等神经网络生成模型的进展，一些工作显示出可喜的结果。 示例包括用于未来运动预测的 HP-GAN [6] 和循环 VAE [22]。 大多数工作将身体视为骨架，尽管最近的工作利用了完整的 3D 身体形状模型 [3, 74]。 与 [74] 类似，我们也超越了稀疏关节并将顶点合并到身体表面。 DLow [71] 侧重于从预训练模型中多样化未来运动的采样。
[11] 使用关于对象交互的上下文线索执行有条件的未来预测。 最近，[42] 提出了一种基于 Transformer 的舞蹈生成方法，该方法以音乐和过去的动作为条件。 段等。 [14] 使用变形金刚完成运动。 有一个关于运动“中间”的相关工作，它采用过去和未来的姿势，并“修复”它们之间的合理运动； 有关更多信息，请参见 [23]。 与之前的工作相比，我们的目标是在没有任何过去观察的情况下合成运动。
人体运动合成。 虽然有大量关于未来预测的文献，但从头开始综合受到的关注相对较少。 非常早期的工作使用 PCA [51] 和 GPLVM [64] 来学习步行和跑步等循环运动的统计模型。 对多种多样的动作进行条件综合要困难得多。 DVGAN [43] 训练一个生成模型，该模型以表示 MoCap 数据集中动作的短文本为条件，例如 Human3.6M [30、31] 和 CMU [63]。 Text2Action [1] 和 Language2Pose [2] 同样探索了根据文本描述调节动作生成。 Music-to-Dance [39] 和 [41] 研究音乐条件生成。 QuaterNet [56] 侧重于在给定地面轨迹和平均速度的情况下生成行走和跑步等运动动作。 [69] 提出了一种基于卷积的生成模型，用于在不指定动作的情况下实现逼真的但不受约束的运动。 类似地，[73] 合成任意序列，关注时间上的无界运动。

无约束运动合成的许多方法往往以步行和跑步等动作为主导。相比之下，我们的模型能够从更一般的，无周期的，预定义的行动类别，与行动识别数据集兼容的样本。在这方面，[75]引入了贝叶斯方法，其中隐藏半马尔可夫模型用于联合训练生成模型和判别模型。与我们类似，[75]表明，他们生成的动作可以作为额外的训练数据的行动识别。然而，根据判别器分类结果，它们生成的序列是伪标记的。另一方面，我们的条件模型能够以一种受控的方式合成运动，例如平衡训练集。与我们的工作最相似的是 Action2Motion [21] ，这是一个基于 GRU 架构的每帧操作 VAE。我们的序列级 VAE 潜在空间，结合基于变压器的设计提供了显著的优势，如我们的实验所示。

其他最近的工作[25,72]使用规范化流来解决人体运动估计和生成问题。几个作品[29,36,67]学习一个运动流形，并使用它的运动去噪，这是我们的用例之一。还有一个重要的图形文献的主题，这往往集中在动画师控制。看，例如，[27]学习动作匹配和[40]角色动画。这里最相关的是相函数神经网络[28]和神经状态机[61]。两者都利用了由正弦函数相位驱动的动作的概念。这与位置编码的思想有关，但与我们的方法不同，它们的方法需要人工分割操作并构建这些相函数。

**单目人体运动估计。**来自视频的运动估计[35,38,47]最近取得了重大进展，但超出了我们的范围。在这项工作中，我们采用 VIBE [38]从动作标记的视频数据集中获得训练运动序列。

**Transformer VAE**。Transformer 最近在语言任务方面取得的成功增加了人们对基于注意力的神经网络模型的兴趣。一些工程使用变压器结合生成 VAE 培训。具体的例子包括故事生成[15] ，情感分析[10] ，反应生成[44]和音乐生成[33]。[33]的工作学习每个时间框架的潜在嵌入，而[10]平均的隐藏状态，以获得一个单一的潜在代码。另一方面，[15]执行注意力平均池随着时间的推移。与这些工作相反，我们采用可学习的标记，如[12,13]中所示，将输入总结为序列级嵌入。

> 图2：方法概述。我们说明了我们基于Transformer的VAE模型的编码器（左）和解码器（右），该模型生成了动作条件的运动。给定一串身体姿势P1, ... , PT和一个动作标签a，编码器输出分布参数，我们在此基础上定义KL损失（LKL）。我们使用每个动作的额外可学习标记（µ token a 和 Σ token a ）作为从Transformer编码器获得µ和Σ的方法。使用µ和Σ，我们对运动的潜在表征z∈M进行采样。解码器将潜伏向量z、动作标签a和持续时间T作为输入。行动决定了可学习的b标记a加法标记，持续时间决定了输入到解码器的位置编码（PE）的数量。解码器输出整个序列Pb1, . . . , PbT，在此基础上计算重建损失LP。此外，我们用一个可微分的SMPL层计算顶点，以定义一个顶点损失（LV ）。对于训练来说，z是作为编码器的输出得到的；对于生成来说，它是从高斯分布中随机抽取的。

## Action-Conditioned Motion Generation

**问题定义。**身体运动所定义的动作可以是身体部位的旋转拥有属性，与身份特定的身体形状无关。为了能够产生与不同形态的行为者的运动，这是理想的分离姿势和形状。因此，不失一般性，我们采用了 SMPL 身体模型[46] ，这是一个分离的身体表示(类似于最近的模型[53,55,58,68])。忽略形状，我们的目标是生成一系列的姿态参数。更正式地说，给定一个动作标签 a (来自一组预定义的动作范畴 a ∈ A)和一个持续时间 T，我们生成一个体构成的序列 R1，... ，RT 和一个根关节的平移序列表示为位移，D1，... ，DT (与 DT ∈ R3，something t ∈{1，... ，T })

**动作表现法。**每帧 SMPL 姿态参数表示运动学树中的23个关节旋转和一个全局旋转。采用连续6D 旋转表示法进行训练[76] ，使 Rt ∈ R24 × 6。设 Pt 是 Rt 和 Dt 的组合，表示单帧中身体的姿势和位置 t。完整的动作是 P1，. . ，PT。给定一个生成器输出位姿 Pt 和任意形状参数，我们可以用[46]可微地得到体网格顶点(Vt)和体关节坐标(Jt)。

### Conditional Transformer VAE for Motions

我们采用条件变分自动编码器(CVAE)模型[60] ，并将动作类别信息输入到编码器和解码器。更具体地说，我们的模型是一个动作条件变压器 VAE (ACTOR) ，其编码器和解码器由变压器层组成(参见图2以获得概述)。

**编码器。**该编码器采用任意长度的姿态序列，以动作标签 a 为输入，输出运动潜伏空间的分布参数 μ 和 Σ。利用重参数化技巧[37] ，我们从这个分布中抽样出一个潜向量 z ∈ M，其中 MdRd。首先将所有输入姿态参数(R)和平移(D)线性嵌入到 Rd 空间中。当我们将任意长度的序列嵌入到一个潜在空间(序列级嵌入)时，我们需要合并时间维数。在其他领域中，已经引入了[类]令牌用于池的目的，例如，在带有 BERT [12]的 NLP 中，以及最近在带有 ViT [13]的计算机视觉中。受此方法的启发，我们类似地在输入前面加上可学习的令牌，并且只使用相应的编码器输出作为汇集时间维度的方法。为此，我们在每个操作中包括两个额外的可学习参数: μ 标记 a 和 Σ 标记 a，我们称之为“分布参数标记”。我们将嵌入的姿势序列附加到这些标记。产生的变压器编码器输入是位置编码的正弦函数形式的总和。我们通过取编码器的前两个输出对应于分布参数标记来获得分布参数 μ 和 Σ (即去掉其余的标记)。解码器。给定一个潜在向量 z 和一个动作标签 a，解码器在一次拍摄中在给定的持续时间内生成一个真实的人体运动(即，不是自回归)。我们使用变压器解码器模型，其中我们提供的时间信息作为一个查询(在 T 正弦位置编码的形式) ，和潜在的向量结合的行动信息，作为关键和值。为了合并动作信息，我们简单地添加一个可学习的偏见 b 标记 a 来将潜在表征转移到一个动作依赖的空间。变压器解码器输出一系列的 T 矢量，从中我们可以得到最终的 Pb1，. . ，PbT 的线性投影。利用可微 SMPL 层获得给定的位姿参数作为解码器输出的顶点和关节。

### Training

我们定义了几个损失项来训练我们的模型，并在第 4.2 节中进行了消融研究。
姿势参数 (LP) 的重建损失。 我们在地面实况姿势 P1,... 之间使用 L2 损失。 . . , PT 和我们的预测 Pb1, . . . , PbT 作为 LP = PT t=1∥Pt − Pbt∥ 2 2 。 请注意，此损失包含 SMPL 旋转和根平移。 当我们通过丢弃平移进行实验时，我们将这个术语分成两部分：LR 和 LD，分别用于旋转和平移。

**顶点坐标 (LV) 上的重建损失。** 我们将 SMPL 姿势 Pt 和 Pbt 馈送到具有平均形状（即 β = ⃗0）的可微分 SMPL 层（没有可学习参数）以获得网格 Vt 和 Vbt 的根中心顶点。 我们通过与地面实况顶点 Vt 比较来定义 L2 损失，即 LV = PT t=1∥Vt − Vbt∥ 2 2 。 我们进一步在一组更稀疏的点上使用损失 LJ 进行实验，例如通过 SMPL 联合回归器获得的联合位置 Jbt。 然而，正如第 4.2 节所示，我们没有在最终模型中包含该术语。
**KL损失（LKL）**。 与标准 VAE 一样，我们通过鼓励潜在空间类似于高斯分布来规范化潜在空间，其中 µ 是空向量，Σ 是身份矩阵。 我们最小化编码器分布和该目标分布之间的 Kullback–Leibler (KL) 散度。
由此产生的总损失被定义为不同项的总和：L = LP + LV + λKLLKL。 我们凭经验证明了在我们的实验中使用 λKL（相当于 β-VAE [26] 中的 β 项）进行加权以获得多样性和现实主义之间的良好权衡的重要性（参见附录 A.1 节） ). 剩余的损失项只是简单地同等加权，通过调整可能会进一步改进。 我们使用固定学习率为 0.0001 的 AdamW 优化器。 小批量大小设置为 20，我们发现性能对这个超参数很敏感（参见附录 A.2 节）。
我们分别在 NTU-13、HumanAct12 和 UESTC 数据集上训练我们的模型 2000、5000 和 1000 个时期。
总的来说，更多的时期会产生更好的性能，但我们停止训练以保持较低的计算成本。 请注意，为了允许更快的迭代、损失和架构的消融，我们在 NTU-13 上训练了 1000 个 epoch，在 UESTC 上训练了 500 个 epoch。 其余的实施细节可以在附录的 C 节中找到。

## Experiments

暂略

## Conclusions

我们提出了一种新的基于 Transformer 的 VAE 模型来合成以动作为条件的人体运动。我们提供了详细的分析来评估我们提议的方法的不同组成部分。 我们在动作条件运动生成方面获得了最先进的性能，与之前的工作相比有了显着改进。 此外，我们探索了运动去噪和动作识别中的各种用例。 我们方法的一个特别吸引人的特性是它在序列级潜在空间上运行。因此，未来的工作可以利用我们的模型对运动估计或动作识别问题施加先验。